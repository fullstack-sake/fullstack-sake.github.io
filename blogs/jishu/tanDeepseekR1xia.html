<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-rc.14">
    <script>
      (function() {
        const userMode = localStorage.getItem('vuepress-reco-color-scheme') || 'auto';
        const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;

        if (userMode === 'dark' || (userMode === 'auto' && systemDarkMode)) {
          document.documentElement.classList.toggle('dark', true);
        }
      })();
    </script>
    <meta property="og:url" content="https://sakee.cn/blogs/jishu/tandeepseekr1xia.html"><meta property="og:site_name" content="sake's blog"><meta property="og:title" content="DeepSeek-R1 技术解析（下）"><meta property="og:description" content="TIP论文链接：https://arxiv.org/abs/2501.12948 前言 在上一篇博客的导读部分，我们提出了多个关键问题，这些问题贯穿了整个技术设计的逻辑链条。 但是原论文分享的训练方法和细节并不多，复现难度还是挺大的。在许多传统观点中，我们认为训练一个具备强大推理能力的语言模型，必须对每一步推导过程进行精细的监督。但Deepseek-R..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="fullstacksake"><meta property="article:tag" content="LLM"><meta property="article:published_time" content="2025-02-01T16:00:00.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"DeepSeek-R1 技术解析（下）","image":[""],"datePublished":"2025-02-01T16:00:00.000Z","dateModified":null,"author":[{"@type":"Person","name":"fullstacksake","email":"fullstacksake@outlook.com"}]}</script><link rel="icon" href="/favicon.ico"><meta name="description" content="SAKE的博客 fullstacksake的技术分享博客"><meta name="viewport" content="width=device-width,initial-scale=0.8,user-scalable=no"><link rel="preconnect" href="https://cdn.jsdelivr.net/npm/@callmebill/lxgw-wenkai-web@latest" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@callmebill/lxgw-wenkai-web@latest/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/daisyui@4.12.23/dist/full.min.css" type="text/css"><script src="https://cdn.tailwindcss.com"></script><title>DeepSeek-R1 技术解析（下） | sake's blog</title>
    <link rel="preload" href="/assets/style-CVzxxlbV.css" as="style"><link rel="stylesheet" href="/assets/style-CVzxxlbV.css">
    <link rel="modulepreload" href="/assets/app-WuGmklff.js"><link rel="modulepreload" href="/assets/tanDeepseekR1xia.html-BDBd__Cb.js">
    
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container series--no show-catalog"><header class="navbar-container not-open"><div class="navbar-inner"><div class="site-brand nav-item"><img class="logo" src="/logo_transparent.webp" alt="sake&#39;s blog"><a href="/" class="site-name can-hide">sake&#39;s blog</a></div><div class="nav-item navbar-links-wrapper" style=""><div><form class="search-box" role="search"><input type="search" autocomplete="off" spellcheck="false" value><!----></form></div><nav class="navbar-links"><!--[--><div class="navbar-links__item"><a href="/posts" class="link" aria-label="博客"><!--[--><!--]--><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:inherit;"><path d="M4 24h10v2H4z" fill="currentColor"></path><path d="M4 18h10v2H4z" fill="currentColor"></path><path d="M26 14H6a2 2 0 0 1-2-2V6a2 2 0 0 1 2-2h20a2 2 0 0 1 2 2v6a2 2 0 0 1-2 2zM6 6v6h20V6z" fill="currentColor"></path><path d="M26 28h-6a2 2 0 0 1-2-2v-6a2 2 0 0 1 2-2h6a2 2 0 0 1 2 2v6a2 2 0 0 1-2 2zm-6-8v6h6v-6z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->博客<!--]--></span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a href="/timeline" class="link" aria-label="归档"><!--[--><!--]--><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:inherit;"><path d="M14 19h4v2h-4z" fill="currentColor"></path><path d="M6 2v26a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V2zm18 26H8V16h16zm0-14H8v-4h16zM8 8V4h16v4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->归档<!--]--></span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a href="/series/shicigefu/introduce" class="link" aria-label="诗词歌赋"><!--[--><!--]--><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:inherit;"><path d="M19 10h7v2h-7z" fill="currentColor"></path><path d="M19 15h7v2h-7z" fill="currentColor"></path><path d="M19 20h7v2h-7z" fill="currentColor"></path><path d="M6 10h7v2H6z" fill="currentColor"></path><path d="M6 15h7v2H6z" fill="currentColor"></path><path d="M6 20h7v2H6z" fill="currentColor"></path><path d="M28 5H4a2.002 2.002 0 0 0-2 2v18a2.002 2.002 0 0 0 2 2h24a2.002 2.002 0 0 0 2-2V7a2.002 2.002 0 0 0-2-2zM4 7h11v18H4zm13 18V7h11v18z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->诗词歌赋<!--]--></span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a href="/series/suibi/introduce" class="link" aria-label="随笔"><!--[--><!--]--><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:inherit;"><path d="M27.307 6.107L30 3.414L28.586 2l-2.693 2.693L24.8 3.6a1.933 1.933 0 0 0-2.8 0l-18 18V28h6.4l18-18a1.933 1.933 0 0 0 0-2.8zM9.6 26H6v-3.6L23.4 5L27 8.6z" fill="currentColor"></path><path d="M9 11.586L16.586 4L18 5.414L10.414 13z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->随笔<!--]--></span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a href="/docs/guide/friends" class="link" aria-label="友链"><!--[--><!--]--><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:inherit;"><path d="M25 10H7a3.003 3.003 0 0 0-3 3v6a2.002 2.002 0 0 0 2 2v7a2.002 2.002 0 0 0 2 2h4a2.002 2.002 0 0 0 2-2V16h-2v12H8v-9H6v-6a1 1 0 0 1 1-1h18a1 1 0 0 1 1 1v6h-2v9h-4V16h-2v12a2.002 2.002 0 0 0 2 2h4a2.002 2.002 0 0 0 2-2v-7a2.002 2.002 0 0 0 2-2v-6a3.003 3.003 0 0 0-3-3z" fill="currentColor"></path><path d="M10 9a4 4 0 1 1 4-4a4.004 4.004 0 0 1-4 4zm0-6a2 2 0 1 0 2 2a2.002 2.002 0 0 0-2-2z" fill="currentColor"></path><path d="M22 9a4 4 0 1 1 4-4a4.004 4.004 0 0 1-4 4zm0-6a2 2 0 1 0 2 2a2.002 2.002 0 0 0-2-2z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->友链<!--]--></span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a href="/docs/guide/about" class="link" aria-label="关于"><!--[--><!--]--><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:inherit;"><path d="M12 4a5 5 0 1 1-5 5a5 5 0 0 1 5-5m0-2a7 7 0 1 0 7 7a7 7 0 0 0-7-7z" fill="currentColor"></path><path d="M22 30h-2v-5a5 5 0 0 0-5-5H9a5 5 0 0 0-5 5v5H2v-5a7 7 0 0 1 7-7h6a7 7 0 0 1 7 7z" fill="currentColor"></path><path d="M22 4h10v2H22z" fill="currentColor"></path><path d="M22 9h10v2H22z" fill="currentColor"></path><path d="M22 14h7v2h-7z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->关于<!--]--></span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a href="/docs/guide/sponsor" class="link" aria-label="赞助者"><!--[--><!--]--><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:inherit;"><circle cx="10" cy="14" r="2" fill="currentColor"></circle><path d="M16 30a1 1 0 0 1-.71-.29L4.59 19A2 2 0 0 1 4 17.59V10a2 2 0 0 1 2-2h7.59a2 2 0 0 1 1.41.59l10.71 10.7a1 1 0 0 1 0 1.42l-9 9A1 1 0 0 1 16 30zM6 10v7.59l10 10L23.59 20l-10-10z" fill="currentColor"></path><path d="M27.71 13.29L17 2.59A2 2 0 0 0 15.59 2H8a2 2 0 0 0-2 2v2h2V4h7.59l10 10l-1.3 1.29l1.42 1.42l2-2a1 1 0 0 0 0-1.42z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->赞助者<!--]--></span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a class="link" href="https://github.com/fullstack-sake/fullstack-sake.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->GitHub<!--]--></span></span><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><!--]--></nav><span class="xicon-container btn-toggle-dark-mode btn--dark-mode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" style="width:20px;height:20px;font-size:20px;color:inherit;"><path d="M15 2h2v3h-2z" fill="currentColor"></path><path d="M27 15h3v2h-3z" fill="currentColor"></path><path d="M15 27h2v3h-2z" fill="currentColor"></path><path d="M2 15h3v2H2z" fill="currentColor"></path><path d="M5.45 6.884l1.414-1.415l2.121 2.122l-1.414 1.414z" fill="currentColor"></path><path d="M23 7.58l2.121-2.12l1.414 1.414l-2.121 2.121z" fill="currentColor"></path><path d="M23.002 24.416l1.415-1.414l2.12 2.122l-1.413 1.414z" fill="currentColor"></path><path d="M5.47 25.13L7.59 23L9 24.42l-2.12 2.12l-1.41-1.41z" fill="currentColor"></path><path d="M16 8a8 8 0 1 0 8 8a8 8 0 0 0-8-8zm0 14a6 6 0 0 1 0-12z" fill="currentColor"></path></svg></span><span class="xicon-container btn-toggle-menus"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" style="width:20px;height:20px;font-size:20px;color:inherit;"><circle cx="16" cy="8" r="2" fill="currentColor"></circle><circle cx="16" cy="16" r="2" fill="currentColor"></circle><circle cx="16" cy="24" r="2" fill="currentColor"></circle></svg></span></div></div></header><!----><!----><!----><!--[--><main class="page-container"><aside class="series-container"><!--[--><!--]--></aside><div class="page-content"><h1 class="page-title">DeepSeek-R1 技术解析（下）</h1><div class="page-info"><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:inherit;"><path d="M16 4a5 5 0 1 1-5 5a5 5 0 0 1 5-5m0-2a7 7 0 1 0 7 7a7 7 0 0 0-7-7z" fill="currentColor"></path><path d="M26 30h-2v-5a5 5 0 0 0-5-5h-6a5 5 0 0 0-5 5v5H6v-5a7 7 0 0 1 7-7h6a7 7 0 0 1 7 7z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->SAKE<!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:inherit;"><path d="M26 4h-4V2h-2v2h-8V2h-2v2H6c-1.1 0-2 .9-2 2v20c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 22H6V12h20v14zm0-16H6V6h4v2h2V6h8v2h2V6h4v4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->2025/02/02<!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:inherit;"><path d="M11.17 6l3.42 3.41l.58.59H28v16H4V6h7.17m0-2H4a2 2 0 0 0-2 2v20a2 2 0 0 0 2 2h24a2 2 0 0 0 2-2V10a2 2 0 0 0-2-2H16l-3.41-3.41A2 2 0 0 0 11.17 4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[--><!--[--><a href="/categories/jishu/1.html" class="">技术</a><!--]--><!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:inherit;"><path d="M10 14a4 4 0 1 1 4-4a4.005 4.005 0 0 1-4 4zm0-6a2 2 0 1 0 1.998 2.004A2.002 2.002 0 0 0 10 8z" fill="currentColor"></path><path d="M16.644 29.415L2.586 15.354A2 2 0 0 1 2 13.941V4a2 2 0 0 1 2-2h9.941a2 2 0 0 1 1.414.586l14.06 14.058a2 2 0 0 1 0 2.828l-9.943 9.943a2 2 0 0 1-2.829 0zM4 4v9.942L18.058 28L28 18.058L13.942 4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[--><!--[--><a href="/tags/LLM/1.html" class="">LLM</a><!--]--><!--]--></span></span><!----></div><div class="theme-reco-md-content"><div><div class="custom-container tip"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="9"></circle><path d="M12 8h.01"></path><path d="M11 12h1v4h1"></path></g></svg><p class="custom-container-title">TIP</p><p>论文链接：https://arxiv.org/abs/2501.12948</p></div><hr><h2 id="前言" tabindex="-1"><a class="header-anchor" href="#前言"><span>前言</span></a></h2><p>在<a href="https://sakee.cn/blogs/jishu/tandeepseekr1.html" target="_blank" rel="noopener noreferrer">上一篇博客<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>的导读部分，我们提出了多个关键问题，这些问题贯穿了整个技术设计的逻辑链条。</p><p>但是原论文分享的训练方法和细节并不多，复现难度还是挺大的。在许多传统观点中，我们认为训练一个具备强大推理能力的语言模型，必须对每一步推导过程进行精细的监督。但<code>Deepseek-R1</code>就是个例外。由此，我们继续深挖<code>Deepseek-R1</code>，从不同的角度来理解是如何奖励信号是如何激发推理能力的。</p><blockquote><p><em>注：这里的<code>Deepseek-R1</code>指<code>Deepseek-R1</code>系列，全文使用<code>R1</code>指代<code>R1</code>模型</em></p></blockquote><h2 id="一、从问题导向到结果导向" tabindex="-1"><a class="header-anchor" href="#一、从问题导向到结果导向"><span>一、从问题导向到结果导向</span></a></h2><p>在很多领域，我们习惯于“事事必查”，特别是在数学问题这种需要严密逻辑推导的任务中。目前大多数<code>benchmark</code>仅关注最终答案，对<code>solution</code>并没有严格要求，现有的改良思路是加入对<code>COT</code>的评判。正因为<code>COT</code>在提升模型推理能力上起到了关键作用，所以大部分模型的训练都会通过大量思考过程引导模型形成<code>COT</code>的范式。</p><p>这样也会出现两个问题：</p><blockquote><p>1.<strong>高昂的数据标注成本</strong>：需要大量人力对每个细节进行精细标注。</p><p>2.<strong>灵活性降低</strong>：过分约束中间过程可能让模型难以自主探索新策略。</p></blockquote><p>然而不同于前面，<code>R1-Zero</code>的设计核心是其实是将数学推理任务转化为一个仅依赖最终结果的<code>End-to-End</code>学习问题。</p><p>简单来说，我们不要求模型是不是按照人类偏好思考，是不是在每个中间步骤都完全正确，只要最终答案正确，然后包裹在<code>\boxed{Answer}</code>，我们就给予正向奖励。</p><h2 id="二、-aha-moment-的再度解读" tabindex="-1"><a class="header-anchor" href="#二、-aha-moment-的再度解读"><span>二、“Aha Moment”的再度解读</span></a></h2><p>在<code>R1-zero</code>的纯<code>RL</code>训练过程中，模型有时会突然发现一种更高效的推理路径，这就是所谓的“顿悟”（<code>Aha Moment</code>）。</p><p>我认为这种现象并非依赖于提前教授某种推理技巧，而是依靠大量的探索得出来的：</p><blockquote><p>1.一方面是<code>GRPO</code>的<strong>在线采样</strong>机制，在每次训练迭代中，模型直接利用当前策略生成候选输出（例如一段<code>COT</code>或答案）。这多种可能的输出，既包括正确的也可能是错误的。</p></blockquote><blockquote><p>2.另一方面是<code>GRPO</code>的<strong>拒绝采样</strong>机制，它在对采样得到的候选输出进行筛选，丢弃低质量的样本。</p></blockquote><p><img src="/assets/GiNuY9jWQAAJa-8-B3d_AWkw.jpg" alt="GRPO"></p><p><strong>在不断的采样后，模型发现候选输出中思考多次的输出奖励会更好。于是他学会了分配更多的思维时间来解决问题。（三思而后行）</strong></p><p>我们没有一个简单明确的数值或标准来衡量模型的<strong>推理深度</strong>。但是我们发现，当模型进入<code>“Aha Moment”</code>时，它往往会生成更多的推理<code>token</code>，这反映出模型在“<strong>花费</strong>”更多计算来进行复杂推理。就像是人的思考过程，有时候会陷入思考，有时候会突然有灵感。</p><p><strong>然而，这样就会造成一个问题：<code>Overthinking</code>（简单问题也会尝试大量的思考以及不断重复的确认自己的答案）</strong></p><h2 id="三、sft-与-rl" tabindex="-1"><a class="header-anchor" href="#三、sft-与-rl"><span>三、SFT 与 RL</span></a></h2><h3 id="_3-1-为什么-r1-zero-选择先进行-rl-而不-sft" tabindex="-1"><a class="header-anchor" href="#_3-1-为什么-r1-zero-选择先进行-rl-而不-sft"><span>3.1 为什么 R1-zero 选择先进行 RL 而不 SFT？</span></a></h3><p>三个方面：</p><blockquote><p>1.直接从<code>Base</code>模型出发，利用<code>RL</code>进行探索，保留<code>Base</code>模型的原始能力。</p></blockquote><blockquote><p>2.高质量的<code>Long-CoT</code>数据较为稀缺，而从现有数据中硬性蒸馏出的<code>CoT</code>可能会限制模型能力（指<s>OpenAI</s>控诉的蒸馏🤐）。</p></blockquote><blockquote><p>3.<code>R1-Zero</code>主要关注在数学问题上取得高分，因此只需要对最终答案进行奖励，而非每个推理步骤都做约束。</p></blockquote><h3 id="_3-2为什么最终的-r1-模型仍然需要-sft-和-preference-learning" tabindex="-1"><a class="header-anchor" href="#_3-2为什么最终的-r1-模型仍然需要-sft-和-preference-learning"><span>3.2为什么最终的 R1 模型仍然需要 SFT 和 Preference Learning？</span></a></h3><p>在<code>R1-Zero</code>训练基础上，<code>R1</code>模型进一步引入了<code>SFT</code>和偏好学习，主要目的在于：</p><blockquote><p>1.引入人类先验，提高可读性，帮助模型控制输出格式，使得生成的推理过程更符合人类思考逻辑。</p></blockquote><blockquote><p>2.不仅限于数学推理，通用数据（如代码、谜题、摘要等）能够使模型推理能力在其他领域得到泛化。</p></blockquote><p>简单来说就是：</p><p><strong><code>R1-Zero</code>是一个“原始智慧”的模型，而<code>R1</code>则像是保留了推理智慧的人类专家。</strong></p><h2 id="四、奖励驱动以及过程监督" tabindex="-1"><a class="header-anchor" href="#四、奖励驱动以及过程监督"><span>四、奖励驱动以及过程监督</span></a></h2><p>或许你会疑问：<strong>奖励驱动能否完全替代过程监督？</strong></p><p><strong>结论是：</strong></p><p>在特定的数学问题上，仅要求最终答案的这中奖励确实足以驱动模型学习出复杂推理能力，过程监督在这一步骤是无效且可以去除的。</p><p>但在开放性任务中（如文本续写）或需要对推理过程进行精细控制的场景下，需要额外的指令微调或过程监督辅助。如果去除人类先验，可能最终只有AI模型能看懂AI模型的“黑箱推理”想表达什么意思了。</p><p><strong>期待的技术演进</strong>：跨任务奖励驱动、分层强化学习、记忆增强机制</p><h2 id="五、结语" tabindex="-1"><a class="header-anchor" href="#五、结语"><span>五、结语</span></a></h2><p><code>R1-Zero</code>的实践证实了<code>End-to-End RL</code>在封闭域推理任务中的潜力，纯<code>RL</code>机制成功激发出模型的“认知涌现”能力。</p><p>接下来的一个关键研究方向就是：<strong>如何将数学推理中习得的抽象逻辑框架高效迁移至蛋白质设计、金融建模等复杂领域。</strong></p><p>同时，<code>DeepSeek-R1</code>在<code>MCTS</code>（蒙特卡洛树搜索）和<code>PRM</code>（过程奖励模型）失败尝试也提供了负样本，这表明：<strong>语言模型推理与传统符号推理在搜索空间、价值估计等维度具有本质的差异。</strong></p></div></div><footer class="page-meta"><div class="meta-item edit-link"><span class="xicon-container left meta-item-label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" class="xicon-icon" style="width:20px;height:20px;font-size:20px;color:inherit;"><path d="M2 26h28v2H2z" fill="currentColor"></path><path d="M25.4 9c.8-.8.8-2 0-2.8l-3.6-3.6c-.8-.8-2-.8-2.8 0l-15 15V24h6.4l15-15zm-5-5L24 7.6l-3 3L17.4 7l3-3zM6 22v-3.6l10-10l3.6 3.6l-10 10H6z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->Edit this page<!--]--></span></span></div><!----></footer><!----><!----></div><div class="page-catalog-container"><h5 class="tip">ON THIS PAGE</h5><ul><!--[--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blogs/jishu/tandeepseekr1xia.html#前言" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="前言"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->前言<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blogs/jishu/tandeepseekr1xia.html#一、从问题导向到结果导向" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="一、从问题导向到结果导向"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->一、从问题导向到结果导向<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blogs/jishu/tandeepseekr1xia.html#二、-aha-moment-的再度解读" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="二、“Aha Moment”的再度解读"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->二、“Aha Moment”的再度解读<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blogs/jishu/tandeepseekr1xia.html#三、sft-与-rl" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="三、SFT 与 RL"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->三、SFT 与 RL<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/jishu/tandeepseekr1xia.html#_3-1-为什么-r1-zero-选择先进行-rl-而不-sft" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="3.1 为什么 R1-zero 选择先进行 RL 而不 SFT？"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->3.1 为什么 R1-zero 选择先进行 RL 而不 SFT？<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/jishu/tandeepseekr1xia.html#_3-2为什么最终的-r1-模型仍然需要-sft-和-preference-learning" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="3.2为什么最终的 R1 模型仍然需要 SFT 和 Preference Learning？"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->3.2为什么最终的 R1 模型仍然需要 SFT 和 Preference Learning？<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blogs/jishu/tandeepseekr1xia.html#四、奖励驱动以及过程监督" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="四、奖励驱动以及过程监督"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->四、奖励驱动以及过程监督<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blogs/jishu/tandeepseekr1xia.html#五、结语" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="五、结语"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:inherit;font-size:14px;"><!--[-->五、结语<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--></ul></div></main><!--[--><!--]--><!--[--><div class="spacer" data-v-d6828784></div><div class="flex justify-center items-center" data-v-d6828784><div tabindex="0" class="collapse collapse-close border-base-300 bg-base-200 border" data-v-d6828784><div class="collapse-title text-xl font-medium" data-v-d6828784><p data-v-d6828784>感谢你愿意驻足阅读我的文字，如需转载/搬运请提前私信联系授权（转载时请完整保留作者信息及原文链接）。</p><p data-v-d6828784>码字不易，如果我的内容曾为你带来过一丝启发或温暖，欢迎通过下方「赞赏」按钮请我喝杯咖啡☕️</p></div><div class="collapse-content" data-v-d6828784><p data-v-d6828784></p></div></div></div><div class="donation" data-v-d6828784><button data-v-d6828784>赞赏</button><div class="main" data-v-d6828784><div class="pic" data-v-d6828784><img src="/image/sponsor/wechat.webp" alt="微信" data-v-d6828784><img src="/image/sponsor/alipay.webp" alt="支付宝" data-v-d6828784></div></div></div><!--]--><!--[--><div class="spacer" data-v-840d9a4d></div><div class="flex justify-center items-center" data-v-840d9a4d><div id="RUI-SPEAK" data-app-id="MTcyMzEwOTM3MjEwNDIxMg==" data-app-key="fr/R8DheRPAS/k5fxSPl88ZEvG9wO3Un8xhX5hKc1ro=" style="width:80%;" data-v-840d9a4d></div></div><!--]--><!--]--></div><!--[--><!----><!----><div></div><!--]--><!--]--></div>
    <script type="module" src="/assets/app-WuGmklff.js" defer></script>
  </body>
</html>
